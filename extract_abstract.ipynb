{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('content', glob=\"**/*.txt\", use_multithreading=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a long document we can split up.\n",
    "with open(\"content/content-0.txt\") as f:\n",
    "    state_of_the_union = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=300,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = text_splitter.create_documents([state_of_the_union])\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# # Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "# raw_documents = TextLoader('../../../state_of_the_union.txt').load()\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "# documents = text_splitter.split_documents(raw_documents)\n",
    "db = Chroma.from_documents(texts, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "      (\"system\", \"You have a long string of data: {data_string}\"),\n",
    "      (\"system\", \"Answer the following question based on the data:\"),\n",
    "      (\"user\", \"{question}\")\n",
    "])\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"You are a world class text extractor.You have to extract the text from the user's input\"),\n",
    "#     (\"user\", \"{input}\")\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The purpose of this study is to present an exhaustive analysis on research paper recommender systems which have become very popular and gained a lot of research attention. Though the major focus is on developing new recommendation algorithms, other research dimensions are left untouched. Renown recommendation classes include content-based approaches, collaborative filtering, link-based algorithms, co-occurrence based approaches, global relevance and hybrid methods. These approaches mainly differ in background knowledge and modes of user behavior analysis. For instance, content-based filtering uses paper descriptions which are mostly word-based features. Collaborative filtering makes predictions based on peers’ interests. Link-based algorithms utilize academic associations that exist between different entities in academia. Co-occurrence based techniques incorporate event occurrences to locate related papers. Global relevance adopts a ‘one-for-all’ policy for recommending popular articles. Hybrid methods combine the above approaches to design efficient algorithms. We have reviewed articles implementing several versions of these classes, however minor customizations make it difficult to categorize the new methods to one of the base classes. We have defined the concept of ‘background knowledge and operating principle’ for proper classification and to make a clear distinction among the recommendation approaches. We have used a combination of systematic literature review, critical review, and conceptual review to conduct this survey which presents current advancements in the field and discusses popular recommendation approaches. This paper reveals the factors affecting users’ behavior and introduces a taxonomy of knowledge acquisition sources. Moreover, various evaluation methods and important performance criteria are explored. Finally, this paper examines the research trends and reports major loopholes in current research to foster the development of efficacious recommender systems.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"data_string\": state_of_the_union,\n",
    "        \"question\": \"extract the abstract without chaing anything\"\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
